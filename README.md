# EHPC: Evaluator Head-based Prompt Compression ì¬í˜„ êµ¬í˜„ì²´

[![Python 3.12+](https://img.shields.io/badge/python-3.12+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-orange.svg)](https://pytorch.org/)
[![HuggingFace](https://img.shields.io/badge/ğŸ¤—-Transformers-yellow.svg)](https://huggingface.co/transformers/)

"Efficient Prompt Compression with Evaluator Heads for Long-Context Transformer Inference" ë…¼ë¬¸ì˜ í•µì‹¬ ì•„ì´ë””ì–´ë¥¼ êµ¬í˜„í•œ ìˆœìˆ˜ Python ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.

## ğŸ¯ í•µì‹¬ ê¸°ëŠ¥

- **ğŸ” Evaluator Heads ìë™ ë°œê²¬**: Needle-in-a-Haystack í…ŒìŠ¤íŠ¸ë¡œ ì¤‘ìš” ì •ë³´ë¥¼ ì‹ë³„í•˜ëŠ” attention head ì°¾ê¸°
- **ğŸ—œï¸ ì§€ëŠ¥í˜• í”„ë¡¬í”„íŠ¸ ì••ì¶•**: attention ê¸°ë°˜ í† í° ì¤‘ìš”ë„ ê³„ì‚°ìœ¼ë¡œ ì •í™•í•œ ì••ì¶•
- **ğŸ“Š ì¢…í•©ì  ë²¤ì¹˜ë§ˆí¬**: SQuAD QA, CNN/DailyMail ìš”ì•½ ë“± ë‹¤ì–‘í•œ íƒœìŠ¤í¬ í‰ê°€
- **ğŸ¨ ì§ê´€ì  ì‹œê°í™”**: attention íŒ¨í„´ê³¼ ì••ì¶• ê²°ê³¼ì˜ ì¸í„°ë™í‹°ë¸Œ ì‹œê°í™”
- **ğŸŒ ì›¹ ë°ëª¨**: Streamlit ê¸°ë°˜ ì‹¤ì‹œê°„ í…ŒìŠ¤íŠ¸ ì¸í„°í˜ì´ìŠ¤

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### ì„¤ì¹˜

```bash
# ì €ì¥ì†Œ í´ë¡ 
git clone https://github.com/your-repo/ehpc-reproduction.git
cd ehpc-reproduction

# ì˜ì¡´ì„± ì„¤ì¹˜
uv sync
```

### ê¸°ë³¸ ì‚¬ìš©ë²•

```python
from core.prompt_compressor import EHPCCompressor

# 1. ì••ì¶•ê¸° ì´ˆê¸°í™”
compressor = EHPCCompressor("microsoft/DialoGPT-medium")
compressor.initialize()  # Evaluator Heads ìë™ ë°œê²¬

# 2. í”„ë¡¬í”„íŠ¸ ì••ì¶•
result = compressor.compress_prompt(
    "Your very long prompt here...",
    compression_ratio=0.3  # 30%ë§Œ ìœ ì§€
)

print(f"ì••ì¶•ë¥ : {result.compression_ratio:.1%}")
print(f"ì••ì¶•ëœ í…ìŠ¤íŠ¸: {compressor.tokens_to_text(result.compressed_tokens)}")

# 3. ì••ì¶• + ìƒì„± (í•œë²ˆì—)
generation_result = compressor.compress_and_generate(
    "Explain machine learning in detail...",
    compression_ratio=0.3,
    max_new_tokens=100
)
```

### ì›¹ ë°ëª¨ ì‹¤í–‰

```bash
# Streamlit ì•± ì‹¤í–‰
uv run streamlit run demo/streamlit_app.py

# ë¸Œë¼ìš°ì €ì—ì„œ ìë™ìœ¼ë¡œ ì—´ë¦½ë‹ˆë‹¤!
```

## ğŸ“š ë…¼ë¬¸ ì°¸ì¡°

```bibtex
@article{wei2025efficient,
  title={Efficient Prompt Compression with Evaluator Heads for Long-Context Transformer Inference},
  author={Wei, Fei and others},
  journal={arXiv preprint arXiv:2501.12959},
  year={2025}
}
```